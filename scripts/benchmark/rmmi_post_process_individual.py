"""
rmmi_post_process_individual.py

This script post-processes the logs generated by the rmmi.py benchmark for robotic manipulation tasks.
It aggregates results from multiple experiment episodes, computes various metrics (such as reachability,
collision status, end-effector accuracy, manipulability, and trajectory distances), and saves detailed
reports as CSV files for each experiment configuration. Failed episodes are tracked and logged separately.

Usage:
    Run the script with command-line arguments specified by PostProcessConfig to process experiment logs
    and generate summary tables.

Main components:
    - PostProcess: Class that loads log data, computes metrics, and generates reports.
    - process_episode: Processes a single episode's log and extracts relevant metrics.
    - loop: Iterates over all experiment configurations and episodes.
    - generate_report: Saves results as CSV files.
    - Main block: Handles CLI arguments and initiates post-processing.
"""
import os
from collections import defaultdict
from itertools import product
from pathlib import Path
import matplotlib.pyplot as plt

import pandas as pd
import tyro
from neural_robot.unity_frankie import NeuralFrankie as Robot
from tqdm import tqdm

from remo_splat import logger
from remo_splat.configs.postprocess import PostProcessConfig

ROBOT = Robot("curobo", spheres = True)

# Script that post process the logs of the rmmi.py benchmark
class PostProcess:
    def __init__(self, args: PostProcessConfig):
        self.args = args
        self.failed = []
        self.results = defaultdict(list)


    def process_episode(self, path, episode_id, key):
        """
        Get the results of a particular episode of a particular variation
        """
        data = logger.LoggerLoader(path, f"{episode_id:04d}", "", None)

        # Reached
        reached = data.reached()

        # Collided
        collided = data.collided()
        if collided:
            self.failed.append(data.data_folder)

        try:
            pred_collided = data.pred_collided()
        except Exception as e:
            pred_collided = False

        try:
            average_distance = data.average_distance()
            min_distance = data.get_min_distance()
            min_pred_distance = data.get_min_pred_distance()
        except Exception as e:
            average_distance = 0
            min_distance = 0
            min_pred_distance = 0

        distance_target = data.get_distance_target()
        len_target = data.get_length_trajectory(ROBOT)
        try:
            acc_eef, cum_acc_eef = logger.acc_eef(data.data, ROBOT, 1/20.)
            acc_eef = acc_eef.mean().item()
        except Exception as e:
            acc_eef = 0
        # Get the time it took to solve the QP
        qp_solving_time = data.get_data("t_qp").mean().item()
        # plt.plot(data.get_data("t_qp"))
        # plt.hlines(data.get_data("t_qp").mean().item(), 0, len(data.get_data("t_qp")), colors='r', linestyles='dashed')
        # plt.title(f"{path}")
        # plt.show()

        average_manipulability = data.average_manipulability(ROBOT)
        successfull = reached and (not collided)

        result = {
                "reached": reached,
                "collided": collided,
                "successfull": successfull,
                "eef_acc": acc_eef,
                "eef_cum_acc": cum_acc_eef[-1],
                "len_target": len_target,
                "episode_id": episode_id,
                "average_manipulability": average_manipulability,
                "average_distance": average_distance,
                "average_manipulability": 0,
                "pred_collided": pred_collided,
                "min_distance": min_distance,
                "min_pred_distance": min_pred_distance,
                "distance_target": distance_target,
                "qp_solving_time": qp_solving_time,
            }

        self.results[key].append(result)

    def loop(self):
        envs = self.args.envs
        sensors = self.args.sensors
        dims = self.args.dimensions

        for env, sensor, dim in tqdm(product(envs, sensors, dims), leave = False):
            key = (env, dim, sensor)
            print(f"Processing {key}")
            full_path = os.path.join("logs/experiments", self.args.get_path(env, dim ,sensor))
            if os.path.isdir(full_path):
                for e in tqdm(range(self.args.n_episodes), leave=False):
                    self.process_episode(self.args.get_path(env, dim, sensor), e, key)
            else:
                print(f"{key} does not exist on the folder {self.args.exp_name}")


        self.generate_report()

    def save_path(self, key):
        return "_".join(key)

    def generate_report(self):
        """Formats and prints the results as a table."""
        path = f"results_tables/details/{self.args.exp_name}"
        os.makedirs(path, exist_ok= True)
        for k, v in self.results.items():
            df = pd.DataFrame(v)
            csv_path = self.save_path(k)
            df.to_csv(f"{path}/{csv_path}.csv")


if __name__ == "__main__":
    import tyro

    args = tyro.cli(PostProcessConfig)

    processor = PostProcess(args)
    processor.loop()
    os.makedirs("results_tables/details/results_" + args.exp_name, exist_ok=True)
    with open(f"results_tables/details/results_{args.exp_name}/failed.txt", 'w') as f:
        for failed in processor.failed:
            f.write(f"{failed}\n")
    print(len(processor.failed))
